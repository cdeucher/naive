{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from machine_learning import split_data\n",
    "\n",
    "import math, random, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  --------------------------------------------------------\n",
    "##  Adicionado nltk para Stemming da palavra\n",
    "##  --------------------------------------------------------\n",
    "import nltk\n",
    "nltk.download()\n",
    "##  d\n",
    "##  punkt\n",
    "##  words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import words\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(message):\n",
    "    message = message.lower() # convert to lowercase\n",
    "    all_words = re.findall(\"[a-z0-9']+\", message) # extract the words\n",
    "    return set(all_words) # remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(training_set):\n",
    "    \"\"\"training set consists of pairs (message, is_spam)\"\"\"\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for message, is_spam in training_set:\n",
    "        for word in tokenize(message):\n",
    "            counts[word][0 if is_spam else 1] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
    "    \"\"\"turn the word_counts into a list of triplets\n",
    "    w, p(w | spam) and p(w | ~spam)\"\"\"\n",
    "    return [(w,\n",
    "        (spam + k) / (total_spams + 2 * k),\n",
    "        (non_spam + k) / (total_non_spams + 2 * k))\n",
    "            for w, (spam, non_spam) in counts.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_probability(word_probs, message):\n",
    "    message_words = tokenize(message)\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
    "\n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
    "\n",
    "        # for each word in the message,\n",
    "        # add the log probability of seeing it\n",
    "        if word in message_words:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "\n",
    "        # for each word that's not in the message\n",
    "        # add the log probability of _not_ seeing it\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "\n",
    "    result = 0 \n",
    "##  --------------------------------------------------------\n",
    "##  probleminha da divisao por 0, entao um try para evita-lo\n",
    "##  -------------------------------------------------------- \n",
    "    try:\n",
    "       result = prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
    "    except:\n",
    "       print('spam_probability',message, prob_if_spam , prob_if_spam , prob_if_not_spam)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "\n",
    "    def train(self, training_set):\n",
    "\n",
    "        # count spam and non-spam messages\n",
    "        num_spams = len([is_spam for message, is_spam in training_set if is_spam])\n",
    "        num_non_spams = len(training_set) - num_spams\n",
    "\n",
    "        # run training data through our \"pipeline\"\n",
    "        word_counts = count_words(training_set)\n",
    "        self.word_probs = word_probabilities(word_counts,\n",
    "                                             num_spams,\n",
    "                                             num_non_spams,\n",
    "                                             self.k)\n",
    "\n",
    "    def classify(self, message):\n",
    "        return spam_probability(self.word_probs, message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  --------------------------------------------------------\n",
    "##  funcao para limpar um pouco do lixo html que vem no email\n",
    "##  é uma piada mas removeu 90% do lixo\n",
    "##  --------------------------------------------------------\n",
    "def is_html(line):\n",
    "    line.lower()\n",
    "    batRegex = re.compile(r'(<[^>]+>|^\\s|@|^=|^#|^http:|style=|^__|^<|^colspan|^valign|^background|^%|^face=|&nbsp;|size=|^table|^meta|^http|^x-|^--|^errors-|th=|^content-|^mime-|^sender|^charset|^date:)')\n",
    "    tag = batRegex.search(line)\n",
    "    #print(line, tag)\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  --------------------------------------------------------\n",
    "##  funcao para fazer o stemming das palavras e aplicar filtro extra\n",
    "##  --------------------------------------------------------\n",
    "def filters(line):   \n",
    "    line.lower()\n",
    "    arr_words = word_tokenize(line)\n",
    "    \n",
    "    for word in arr_words :\n",
    "        if len(word) <= 1 or word == '':\n",
    "            word = ps.stem(word)\n",
    "            arr_words.remove(word)\n",
    "\n",
    "    clear = ','.join(arr_words)\n",
    "    clear = re.sub(',', ' ', clear)\n",
    "\n",
    "    return clear    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_subject_data(path):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # regex for stripping out the leading \"Subject:\" and any spaces after it\n",
    "    subject_regex = re.compile(r\"^Subject:\\s+\")\n",
    "\n",
    "    # glob.glob returns every filename that matches the wildcarded path\n",
    "    for fn in glob.glob(path):\n",
    "        is_spam = \"ham\" not in fn\n",
    "\n",
    "        with open(fn,'r',encoding='ISO-8859-1') as file:\n",
    "            start = 0\n",
    "            for line in file:   \n",
    "##  --------------------------------------------------------\n",
    "##  diversas alteracoes para realizar a leitura do contúdo da \n",
    "##  mensagem após o titulo\n",
    "##  -------------------------------------------------------- \n",
    "                if line.startswith(\"Subject:\"):\n",
    "                    subject = subject_regex.sub(\"\", line).strip()\n",
    "                    subject = filters(subject)\n",
    "                    data.append((subject, is_spam))                    \n",
    "                    start = 1\n",
    "                elif line.startswith(\" \") and start == 1:\n",
    "                    start = 2\n",
    "                elif start == 2  and is_html(line) == None:\n",
    "                    subject = filters(line)\n",
    "                    data.append((subject, is_spam))                    \n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_spam_given_word(word_prob):\n",
    "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(path):\n",
    "\n",
    "    data = get_subject_data(path)\n",
    "    \n",
    "    random.seed(0)      # just so you get the same answers as me\n",
    "    train_data, test_data = split_data(data, 0.75)\n",
    "\n",
    "    classifier = NaiveBayesClassifier()\n",
    "    classifier.train(train_data)\n",
    "\n",
    "    classified = [(subject, is_spam, classifier.classify(subject))\n",
    "              for subject, is_spam in test_data]\n",
    "\n",
    "    counts = Counter((is_spam, spam_probability > 0.5) # (actual, predicted)\n",
    "                     for _, is_spam, spam_probability in classified)\n",
    "\n",
    "    print() \n",
    "    print(counts)\n",
    "    print()\n",
    "    \n",
    "    classified.sort(key=lambda row: row[2])\n",
    "    spammiest_hams = list(filter(lambda row: not row[1], classified))[-5:]\n",
    "    hammiest_spams = list(filter(lambda row: row[1], classified))[:5]\n",
    "\n",
    "    print(\"spammiest_hams\", spammiest_hams)\n",
    "    print()\n",
    "    print(\"hammiest_spams\", hammiest_spams)\n",
    "    print()\n",
    "    \n",
    "    words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
    "\n",
    "    spammiest_words = words[-5:]\n",
    "    hammiest_words = words[:5]\n",
    "\n",
    "    print(\"spammiest_words\", spammiest_words)\n",
    "    print()    \n",
    "    print(\"hammiest_words\", hammiest_words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counter({(False, True): 16964, (True, True): 2867})\n",
      "\n",
      "spammiest_hams [('*******************************************************************************', False, 0.9469633595449223), ('subscription info and how to use it to change it or unsubscribe from', False, 0.9469633595449223), ('In addition to the URL interfaces you can also use email to make such', False, 0.9469633595449223), (\"containing just the word 'help in the message body and an email\", False, 0.9469633595449223), ('message will be sent to you with instructions', False, 0.9469633595449223)]\n",
      "\n",
      "hammiest_spams [('your', True, 0.9469633595449223), ('to The', True, 0.9469633595449223), ('and', True, 0.9469633595449223), ('', True, 0.9469633595449223), ('ce', True, 0.9469633595449223)]\n",
      "\n",
      "spammiest_words [('217', 0.0023951396191143827, 9.815469179426777e-06), ('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 0.0026288117770767614, 9.815469179426777e-06), ('optout', 0.004498189040775791, 9.815469179426777e-06), ('insuranceiq', 0.004615025119756981, 9.815469179426777e-06), ('iiq', 0.005549713751606496, 9.815469179426777e-06)]\n",
      "\n",
      "hammiest_words [('hits', 5.8418039490594695e-05, 0.02205535924617197), ('wrote', 5.8418039490594695e-05, 0.011062033765213978), ('linux', 5.8418039490594695e-05, 0.009138201806046329), ('mailman', 5.8418039490594695e-05, 0.008294071456615626), ('exmh', 5.8418039490594695e-05, 0.00815665488810365)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_and_test_model(r\"./emails/*/*\")\n",
    "    #train_and_test_model(r\"./test/*/*\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
